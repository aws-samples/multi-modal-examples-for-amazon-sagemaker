{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0ee017-04e7-436f-9348-c85588c6c5ae",
   "metadata": {},
   "source": [
    "# Optional: Run evaluation on your fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2af3d-61d7-4952-a29c-de94e0a5ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdd1e8-e34d-41bb-9640-99b4c476e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f841c7-96c9-4b31-86ae-87fe3e1d2712",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F29D9F; border-left: 5px solid #FC0307; padding: 10px; color: black;\">\n",
    "    Please wait 3-5 seconds for the kernel to restart\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ea5c6-2953-43d4-807c-a2570958e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from IPython.display import JSON, Video\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7429c-b8b3-42f5-ae52-31e007d973d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker.session.Session().boto_region_name\n",
    "session = sagemaker.Session()\n",
    "default_bucket_name = session.default_bucket()\n",
    "dataset_dir = \"./local_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9514032-c72c-4cac-88e9-3f513d314692",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = snapshot_download(\n",
    "    repo_id=\"malterei/LLaVA-Video-small-swift\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=dataset_dir\n",
    ")\n",
    "print(f\"Downloaded dataset to local filepath: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb61ee-97e3-4c9e-a6f3-03d140fb8b78",
   "metadata": {},
   "source": [
    "## Get the fine-tuned model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145225e4-2a1b-483f-97dd-414e7e2e27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prefix = 'multi-modal-finetune'\n",
    "models_list_s3 = !aws s3api list-objects-v2 --bucket {default_bucket_name} --prefix {base_prefix} --query \"Contents[?contains(Key, 'output/model.tar.gz')]|sort_by(@, &LastModified)[-1].Key\" --output text\n",
    "print(f\"found {models_list_s3[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43e508-33d1-4662-91a6-a57a415cade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_suffix_s3 = models_list_s3[0]\n",
    "model_s3_path = os.path.join(\"s3://\", default_bucket_name, model_suffix_s3)\n",
    "print(f\"Fine-tuned Model Adapter: {model_s3_path}\")\n",
    "\n",
    "if not model_s3_path.endswith(\"model.tar.gz\"):\n",
    "    assert False, \"No latest fine-tuning found. Did your fine-tuning finish?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153698c-b739-4ee7-896e-7650034b2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_dir = \"./model\"\n",
    "model_destination = f\"{model_weights_dir}/{model_suffix_s3}\"\n",
    "model_dest_dir = str(Path(model_destination).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc213f-acac-45db-a76c-19bc522f6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {model_s3_path} {model_destination}\n",
    "!tar -xzvf {model_destination} --directory {model_dest_dir} > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9d338-f663-471b-93fa-aa67fdbed78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_identifier = \"qwen2-vl-2b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6ac78-f0d6-43b4-becd-6e604e56a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(model_dest_dir, model_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c2d585-2526-4e02-ab43-59d58dfcd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import find_latest_version_directory, find_best_model_checkpoint\n",
    "\n",
    "latest_version = find_latest_version_directory(model_dir)\n",
    "logging_file = os.path.join(os.getcwd(), model_dir, latest_version, \"logging.jsonl\")\n",
    "best_model_checkpoint = find_best_model_checkpoint(logging_file)\n",
    "if best_model_checkpoint:\n",
    "    best_model_checkpoint = best_model_checkpoint.replace(\"/opt/ml/model/\",\"\")\n",
    "    print(f\"best model checkpoint: {best_model_checkpoint}\")\n",
    "else:\n",
    "    print(\"Best model checkpoint not found. Please search the logs manually to find the path that stores the best model checkpoint.\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e6c09-c7ea-45f1-b541-b3638c64f51e",
   "metadata": {},
   "source": [
    "## Run Batch Inference for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62bf64-549b-4608-8c62-579f4b9005a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = \"test.jsonl\"\n",
    "eval_results_path = \"outputs\"\n",
    "model_ckpt_path = os.path.join(\"..\", model_dest_dir, best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2526fa-5705-4d1c-a0f6-adfae8473b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swift.llm import (\n",
    "    InferArguments, ModelType, infer_main, merge_lora\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "import json\n",
    "\n",
    "model_type = ModelType.qwen2_vl_2b_instruct\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.environ[\"NFRAMES\"]=json.dumps(24) # can be increased, but will require more memory\n",
    "os.environ[\"MAX_PIXELS\"]=json.dumps(100352) #400*28*28 # can be increased, but will require more memory\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # devices to be used\n",
    "os.environ[\"NPROC_PER_NODE\"]=\"4\" # we have 4 GPUs on this instance\n",
    "os.environ[\"USE_HF\"]=\"1\" # use huggingface\n",
    "\n",
    "old_work_dir = os.getcwd()\n",
    "os.chdir(dataset_dir)\n",
    "\n",
    "try:\n",
    "    infer_args = InferArguments(\n",
    "        model_type=model_type,\n",
    "        ckpt_dir=model_ckpt_path,\n",
    "        result_dir=os.path.join(\"..\",eval_results_path),\n",
    "        val_dataset=test_data_file,\n",
    "        max_length=2048\n",
    "    )\n",
    "    \n",
    "    # merge_lora(infer_args, device_map='cuda:0')\n",
    "    \n",
    "    infer_main(infer_args)\n",
    "finally:\n",
    "    os.chdir(old_work_dir)\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b461f3b-2a24-4067-b824-14652663d1f5",
   "metadata": {},
   "source": [
    "## Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff55baf-b8ca-4e15-9a4b-856c862bb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install evaluate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b19a9-6a7e-4669-a037-39e75fe91227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef72f91-2081-4e32-9373-7612b5c9ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = evaluate.load(\"exact_match\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922730da-c1d9-4718-b525-b56c284be4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_jsonl(directory):\n",
    "    # Get all jsonl files\n",
    "    files = [f for f in os.listdir(directory) if f.endswith('.jsonl')]\n",
    "    \n",
    "    if not files:\n",
    "        return None\n",
    "    \n",
    "    # Sort by filename (timestamp) and get the latest\n",
    "    latest_file = sorted(files, reverse=True)[0]\n",
    "    \n",
    "    return os.path.join(directory, latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861ed86-fb80-4f23-a8ed-7921399c3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_choice(text):\n",
    "    \"\"\"Extract the letter choice (A, B, C, or D) from text\"\"\"\n",
    "    # Match first occurrence of A, B, C, or D, followed by optional dot or period\n",
    "    match = re.search(r'^([ABCD])[.\\s]?', str(text).strip())\n",
    "    return match.group(1) if match else text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093fd06-0f4f-4a81-8707-e119fc6a36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df):\n",
    "    # Apply the function to create new columns\n",
    "    df['label_choice'] = df['label'].apply(extract_choice)\n",
    "    df['response_choice'] = df['response'].apply(extract_choice)\n",
    "    results = exact_match.compute(\n",
    "        references=df['label_choice'].tolist(),\n",
    "        predictions=df['response_choice'].tolist(),\n",
    "        ignore_case=True,  # Ignore case differences\n",
    "        ignore_punctuation=True  # Ignore punctuation differences\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985e39e-dac7-4951-a21e-17c1e8d62372",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2_2b_fine_tuned_responses_file = find_latest_jsonl(eval_results_path)\n",
    "qwen2_2b_fine_tuned_responses = pd.read_json(qwen2_2b_fine_tuned_responses_file, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b12fa-8c6e-427a-b6e7-35503f17e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of fine-tuned model:\")\n",
    "calculate_accuracy(qwen2_2b_fine_tuned_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94219c-3e56-4b44-93ae-950631b7cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2_2b_fine_tuned_responses.to_json(\"./evaluation/qwen2-vl-2b-instruct/small/outputs.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e719f9-f56b-4a0f-9fdb-d9493c7d7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2_2b_fine_tuned_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779e444-21f9-43ab-9f22-6fc62b2819ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show incorrect predictions\n",
    "incorrect = qwen2_2b_fine_tuned_responses[qwen2_2b_fine_tuned_responses['label_choice'] != qwen2_2b_fine_tuned_responses['response_choice']]\n",
    "print(\"\\nIncorrect predictions:\")\n",
    "incorrect[['label', 'response', 'label_choice', 'response_choice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb0775-45f1-4650-b207-dd1e3ecd34b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
