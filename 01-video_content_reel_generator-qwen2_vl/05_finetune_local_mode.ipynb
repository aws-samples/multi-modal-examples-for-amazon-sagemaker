{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72dab9ad-468b-4667-b6d4-bdd1866a6ef2",
   "metadata": {},
   "source": [
    "# Local-LLM Fine-Tuning of Vid-LLM for improved performance\n",
    "\n",
    "In the previous lab, you performed fine-tuning using a remote SageMaker training job. If your pipeline works, this is a very cost effective way to utilize GPU resources.\n",
    "When running the training job, sometimes you wait for quiet some time, only to discover that the training job failed because of a small code issue.\n",
    "\n",
    "To achieve a faster developer iterations, we will learn how to fine-tune a Video-Language Model (Vid-LLM) locally using Sagemaker Local-Mode. \n",
    "We'll use the Qwen2-VL-2B-Instruct model and apply the LoRA (Low-Rank Adaptation) fine-tuning technique.\n",
    "\n",
    "In this lab you will learn how to,\n",
    "1. Set Up Docker Environment\n",
    "2. Download Training Dataset: We'll use the [LLaVA-Video-sm                                                                   all-swift](https://huggingface.co/datasets/malterei/LLaVA-Video-small-swift) dataset for fine-tuning\n",
    "3. Create config.yaml with necessary settings for local GPU execution\n",
    "4. Define Fine-tuning Function and pipeline using SageMaker\n",
    "5. Create the fine-tuning function using [MS-SWIFT framework](https://github.com/modelscope/ms-swift)\n",
    "5. Create and Run Pipeline in local mode\n",
    "\n",
    "After completing this lab, you will have:\n",
    "\n",
    "* A fine-tuned Vid-LLM model optimized for your specific use case.\n",
    "* Understanding of local fine-tuning process using SageMaker local mode.\n",
    "* Experience with MS-SWIFT framework for video-language models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d31d3-e0b8-479e-9146-76cff9d91cff",
   "metadata": {},
   "source": [
    "## 1. Set Up Docker Environment\n",
    "\n",
    "First, we'll install Docker to handle our containerized workloads and \n",
    "validate the Docker installation by running the `docker version` command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953a548-465c-4404-8bb9-d0af6930fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# see https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y ca-certificates curl\n",
    "sudo install -m 0755 -d /etc/apt/keyrings\n",
    "sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n",
    "sudo chmod a+r /etc/apt/keyrings/docker.asc\n",
    "\n",
    "# Add the repository to Apt sources:\n",
    "echo \\\n",
    "  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n",
    "  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n",
    "  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "sudo apt-get update\n",
    "\n",
    "## Currently only Docker version 20.10.X is supported in Studio: see https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-local.html\n",
    "# pick the latest patch from:\n",
    "# apt-cache madison docker-ce | awk '{ print $3 }' | grep -i 20.10\n",
    "VERSION_STRING=5:20.10.24~3-0~ubuntu-jammy\n",
    "sudo apt-get install docker-ce-cli=$VERSION_STRING docker-compose-plugin -y\n",
    "\n",
    "# validate the Docker Client is able to access Docker Server at [unix:///docker/proxy.sock]\n",
    "docker version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953c1c4-22d7-400a-840f-7a1cb6fe8e9e",
   "metadata": {},
   "source": [
    "## 2. Download Training Dataset\n",
    "\n",
    "We'll use the [LLaVA-Video-small-swift](https://huggingface.co/datasets/malterei/LLaVA-Video-small-swift) dataset for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875e498-f080-4161-8d3f-01ed58884789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.session import Session\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "default_bucket_name = Session().default_bucket()\n",
    "dataset_dir = \"./data/\"\n",
    "dataset_dir_s3 = f\"s3://{default_bucket_name}/mydataset/\"\n",
    "\n",
    "file_path = snapshot_download(\n",
    "    repo_id=\"malterei/LLaVA-Video-small-swift\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=dataset_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699cea9f-d3de-44cd-ba9d-0a478c36c601",
   "metadata": {},
   "source": [
    "## 3. Configure SageMaker Environment\n",
    "\n",
    "Set up the configuration for local GPU execution:\n",
    "\n",
    "* Creates a YAML configuration file named `config.yaml` for the SageMaker Remote Function.\n",
    "* `ImageUri:` the Docker image to use, e.g. Sagemaker distribution 1.11 - `public.ecr.aws/sagemaker/sagemaker-distribution:1.11-gpu`.\n",
    "* `InstanceType:` We use `local_gpu` to make sure that the local mode will run with GPU enabled.\n",
    "* `Dependencies:` We use `./requirements.txt` to add additional packages.\n",
    "* `IncludeLocalWorkDir:` Makes sure to include the local working directory.\n",
    "* `PreExecutionCommands:` Sets the permissions for the `/opt/ml/model` directory. Add any additional commands you might need as preparation.\n",
    "* `CustomFileFilter:` File patterns to ignore when uploading the local work directory for remote exection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ad0a2-1d41-4cf8-a5ae-ab9d89d61d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml = f\"\"\"\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "  PythonSDK:\n",
    "    Modules:\n",
    "      RemoteFunction:\n",
    "        # role arn is not required if in SageMaker Notebook instance or SageMaker Studio\n",
    "        # Uncomment the following line and replace with the right execution role if in a local IDE\n",
    "        # RoleArn: <replace the role arn here>\n",
    "        # S3RootUri: <replace with bucket prefix>\n",
    "        ImageUri: \"public.ecr.aws/sagemaker/sagemaker-distribution:1.11-gpu\"\n",
    "        InstanceType: local_gpu\n",
    "        Dependencies: ./requirements.txt\n",
    "        IncludeLocalWorkDir: true\n",
    "        PreExecutionCommands:\n",
    "        - \"sudo chmod -R 777 /opt/ml/model\"\n",
    "        - \"pip install packaging\"\n",
    "        CustomFileFilter:\n",
    "          IgnoreNamePatterns:\n",
    "          - \"data/*\"\n",
    "          - \"output/*\"\n",
    "          - \"accelerate/*\"\n",
    "          - \"container/*\"\n",
    "          - \"ms-swift/*\"\n",
    "          - \"models/*\"\n",
    "          - \"*.ipynb\"\n",
    "          - \"__pycache__\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(config_yaml, file=open('config.yaml', 'w'))\n",
    "print(config_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf8cf3-46d6-434e-919b-9110208e0050",
   "metadata": {},
   "source": [
    "This cell sets an environment variable `SAGEMAKER_USER_CONFIG_OVERRIDE` to the current working directory. This environment variable is used by SageMaker to load the `config.yaml` file created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833fdb1-0b0d-4508-b256-2e135d8d4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde23f1-44c7-4248-95ee-86e378571e5a",
   "metadata": {},
   "source": [
    "## 4. Define Fine-tuning Function\n",
    "\n",
    "Create the fine-tuning function using the [MS-SWIFT framework](https://github.com/modelscope/ms-swift):\n",
    "\n",
    "The Key Parameters\n",
    "\n",
    "  * **Model**: Qwen2-VL-2B-Instruct\n",
    "  * **Fine-tuning Method**: LoRA (Low-Rank Adaptation)\n",
    "  * **NFRAMES**: The number of frames for video used for model inputs.\n",
    "  * **MAX_PIXELS**: Maximum Resolution: 313600 pixels, e.g. 400x28x28.\n",
    "  * **GPU Configuration**: `CUDA_VISIBLE_DEVICES` Determines how many GPU devices will be used for trainin.\n",
    "\n",
    "For addtional parameters see the [ms-swift cli documentation](https://github.com/modelscope/ms-swift/blob/main/docs/source_en/Instruction/Command-line-parameters.md).\n",
    "\n",
    "This is a simplified version of the fine-tuning process for demonstration purposes. For production use cases, you might want to adjust parameters like frame count and resolution.\n",
    "\n",
    "This pipeline requires a `g5.2xlarge` to run in local mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e017a-3379-4b2d-bda0-c17e8946657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "def fine_tune_video(training_data_s3, train_data_path=\"train.jsonl\",validation_data_path=\"validation.jsonl\"):\n",
    "    from swift.llm.utils import SftArguments\n",
    "    from swift.llm.sft import llm_sft, get_sft_main\n",
    "\n",
    "    ## copy the training data from input source to local directory\n",
    "    dataset_dir = \".\"\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    subprocess.run(['aws', 's3', 'cp', training_data_s3, dataset_dir, '--recursive'])\n",
    "    train_data_local_path = os.path.join(dataset_dir, train_data_path)\n",
    "    validation_data_local_path = os.path.join(dataset_dir, validation_data_path)\n",
    "\n",
    "    # # Set training parameters run the fine-tuning using ms-swift framework\n",
    "    sft_main = get_sft_main(SftArguments, llm_sft)\n",
    "    \n",
    "    os.environ[\"NFRAMES\"]=json.dumps(2) # The number of frames for video used for model inputs\n",
    "    os.environ[\"MAX_PIXELS\"]=json.dumps(78400) # Resolution setting, 100*28*28 for demo purposes only, should be increased for production\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # devices to be used\n",
    "    os.environ[\"NPROC_PER_NODE\"]=\"1\"\n",
    "\n",
    "    # Configure fine-tuning arguments\n",
    "    argv = [\n",
    "        '--model_type', 'qwen2-vl-2b-instruct',\n",
    "        '--model_id_or_path', 'Qwen/Qwen2-VL-2B-Instruct', \n",
    "        '--sft_type', 'lora', \n",
    "        '--output_dir', '/opt/ml/model' ,\n",
    "        '--max_length', '1048',\n",
    "        '--dataset', train_data_local_path, \n",
    "        '--val_dataset', validation_data_local_path]\n",
    "    \n",
    "    sft_main(argv)\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3b7e8-7145-4158-94db-20afb651421f",
   "metadata": {},
   "source": [
    "## 5. Create and Run Pipeline\n",
    "\n",
    "Defines a function that:\n",
    "- Sets up a SageMaker training pipeline\n",
    "- Configures training steps using the previously defined fine-tuning function\n",
    "- Handles pipeline execution in local mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc07e6b-8bdc-4eba-aafa-c9f9c1a28a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import boto3\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# import mlflow\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "\n",
    "def run_pipeline(local_mode=True):\n",
    "\n",
    "    train_result = step(fine_tune_video, name=\"finetune\")(dataset_dir_s3)\n",
    "    steps = [train_result]\n",
    "    \n",
    "    role = get_execution_role()\n",
    "    local_pipeline_session = LocalPipelineSession()\n",
    "    more_params = {}\n",
    "    if local_mode:\n",
    "        more_params[\"sagemaker_session\"] = local_pipeline_session \n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        name=\"projectz\",\n",
    "        parameters=[],\n",
    "        steps=steps,\n",
    "        pipeline_definition_config=PipelineDefinitionConfig(use_custom_job_prefix=True),        \n",
    "        **more_params\n",
    "    )\n",
    "\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21273f6-3a58-49e9-b4e8-1b9710d7fed5",
   "metadata": {},
   "source": [
    "Executes the pipeline in local mode by calling `run_pipeline(local_mode=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f312f38-662f-4e18-9174-5ca4a8cf3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(local_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3523f6a-a31b-4900-a3d8-8699e06711d4",
   "metadata": {},
   "source": [
    "Observe the execution of the pipeline using local mode with docker and docker-compose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7ed00-d56c-4d6d-85b6-17b15177d73d",
   "metadata": {},
   "source": [
    "### Troubleshooting\n",
    "Error: `9olvadyii5-sagemaker-local  | RuntimeError: DataLoader worker (pid(s) 335) exited unexpectedly`.\n",
    "\n",
    "If you see this error, it means the following:\n",
    "\n",
    "* We managed to start the execution of a Sagemaker pipeline locally using docker and docker-compose.\n",
    "  * The local container to run the pipeline was set up correctly\n",
    "  * The training dataset was downloaded correctly\n",
    "  * The model was downloaded correctly\n",
    "  * Fine-tuning started loading the dataset\n",
    "* Loading the dataset failed due to unsufficient memory: Make sure that you have at least a `g5.2xlarge` to have enough CPU Memory for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa179813-8e9e-4d8b-8b90-d011f2f11584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8cc49-d302-4039-bfa3-13e1d01dc3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
